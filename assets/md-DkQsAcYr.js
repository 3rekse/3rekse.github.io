import{o as r,c as l,k as s,e,ac as t,q as m,s as u,B as n}from"./modules/vue-C12uiUEh.js";import{I as c}from"./slidev/default-MSHzuDV9.js";import{u as p,f as d}from"./slidev/context-CklgYWs0.js";import"./index-Dj2O_t2g.js";import"./modules/shiki-BBIst5IO.js";const L={__name:"ai.md__slidev_723",setup(f){const{$slidev:g,$nav:z,$clicksContext:a,$clicks:v,$page:_,$renderContext:h,$frontmatter:i}=p();return a.setup(),(x,o)=>(r(),l(c,m(u(n(d)(n(i),722))),{default:s(()=>o[0]||(o[0]=[e("p",null,[e("strong",null,"Omarillo-3:"),t(" ⚖️ "),e("em",null,'"Ottima domanda. In questi casi, la responsabilità etica ricade sull’intenzione umana. L’IA è uno strumento, ma gli esseri umani sono coloro che ne decidono l’uso."')],-1),e("p",null,[e("strong",null,"Studente-4:"),t(" 😤 "),e("em",null,'"Però non è così semplice. Un algoritmo potrebbe creare situazioni di cyberbullismo senza un’intenzione diretta. Ad esempio, una piattaforma che promuove contenuti controversi per ottenere più interazioni."')],-1),e("p",null,[e("strong",null,"Omarillo-4:"),t(" 📈 "),e("em",null,'"Esattamente. Le piattaforme possono amplificare il male involontariamente. Per questo è fondamentale progettare sistemi etici che minimizzino questi rischi."')],-1),e("p",null,[e("strong",null,"Studente-5:"),t(),e("em",null,'"Ma anche se l’intenzione non è diretta, l’effetto sulla vittima è lo stesso. Le emozioni che prova sono reali."')],-1),e("p",null,[e("strong",null,"Omarillo-5:"),t(" 🌐 "),e("em",null,'"Proprio così. Questo dimostra che la linea tra reale e artificiale non conta quando si tratta delle conseguenze emotive. La sofferenza è reale, indipendentemente da come è generata."')],-1)])),_:1},16))}};export{L as default};
