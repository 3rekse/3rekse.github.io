import{b as r,o as l,w as s,g as e,C as t,v as m,x as u,B as n}from"./modules/vue-BXqLZby3.js";import{I as c}from"./slidev/default-Lu1wnWx6.js";import{u as p,f as d}from"./slidev/context-DrQLX2ti.js";import"./index-u5-TipB0.js";import"./modules/shiki-D1VZkxQz.js";const b={__name:"ai.md__slidev_815",setup(f){const{$clicksContext:a,$frontmatter:i}=p();return a.setup(),(g,o)=>(l(),r(c,m(u(n(d)(n(i),814))),{default:s(()=>o[0]||(o[0]=[e("p",null,[e("strong",null,"Omarillo-3:"),t(" âš–ï¸ "),e("em",null,'"Ottima domanda. In questi casi, la responsabilitÃ  etica ricade sullâ€™intenzione umana. Lâ€™IA Ã¨ uno strumento, ma gli esseri umani sono coloro che ne decidono lâ€™uso."')],-1),e("p",null,[e("strong",null,"Studente-4:"),t(" ğŸ˜¤ "),e("em",null,'"PerÃ² non Ã¨ cosÃ¬ semplice. Un algoritmo potrebbe creare situazioni di cyberbullismo senza unâ€™intenzione diretta. Ad esempio, una piattaforma che promuove contenuti controversi per ottenere piÃ¹ interazioni."')],-1),e("p",null,[e("strong",null,"Omarillo-4:"),t(" ğŸ“ˆ "),e("em",null,'"Esattamente. Le piattaforme possono amplificare il male involontariamente. Per questo Ã¨ fondamentale progettare sistemi etici che minimizzino questi rischi."')],-1),e("p",null,[e("strong",null,"Studente-5:"),t(),e("em",null,'"Ma anche se lâ€™intenzione non Ã¨ diretta, lâ€™effetto sulla vittima Ã¨ lo stesso. Le emozioni che prova sono reali."')],-1),e("p",null,[e("strong",null,"Omarillo-5:"),t(" ğŸŒ "),e("em",null,'"Proprio cosÃ¬. Questo dimostra che la linea tra reale e artificiale non conta quando si tratta delle conseguenze emotive. La sofferenza Ã¨ reale, indipendentemente da come Ã¨ generata."')],-1)])),_:1,__:[0]},16))}};export{b as default};
