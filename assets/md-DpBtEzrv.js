import{o as r,c as l,k as s,e,C as t,q as m,s as u,B as n}from"./modules/vue-BZNZ8Dvd.js";import{I as c}from"./slidev/default-Bhi3UAHz.js";import{u as p,f as d}from"./slidev/context-Ct6ukhQG.js";import"./index-CEdfyKoQ.js";import"./modules/shiki-Vdy54MD1.js";const C={__name:"ai.md__slidev_772",setup(f){const{$slidev:g,$nav:z,$clicksContext:a,$clicks:v,$page:_,$renderContext:h,$frontmatter:i}=p();return a.setup(),(x,o)=>(r(),l(c,m(u(n(d)(n(i),771))),{default:s(()=>o[0]||(o[0]=[e("p",null,[e("strong",null,"Omarillo-3:"),t(" ⚖️ "),e("em",null,'"Ottima domanda. In questi casi, la responsabilità etica ricade sull’intenzione umana. L’IA è uno strumento, ma gli esseri umani sono coloro che ne decidono l’uso."')],-1),e("p",null,[e("strong",null,"Studente-4:"),t(" 😤 "),e("em",null,'"Però non è così semplice. Un algoritmo potrebbe creare situazioni di cyberbullismo senza un’intenzione diretta. Ad esempio, una piattaforma che promuove contenuti controversi per ottenere più interazioni."')],-1),e("p",null,[e("strong",null,"Omarillo-4:"),t(" 📈 "),e("em",null,'"Esattamente. Le piattaforme possono amplificare il male involontariamente. Per questo è fondamentale progettare sistemi etici che minimizzino questi rischi."')],-1),e("p",null,[e("strong",null,"Studente-5:"),t(),e("em",null,'"Ma anche se l’intenzione non è diretta, l’effetto sulla vittima è lo stesso. Le emozioni che prova sono reali."')],-1),e("p",null,[e("strong",null,"Omarillo-5:"),t(" 🌐 "),e("em",null,'"Proprio così. Questo dimostra che la linea tra reale e artificiale non conta quando si tratta delle conseguenze emotive. La sofferenza è reale, indipendentemente da come è generata."')],-1)])),_:1},16))}};export{C as default};
