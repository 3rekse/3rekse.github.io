import{b as r,o as l,w as s,g as e,C as t,v as m,x as u,B as n}from"./modules/vue-BXqLZby3.js";import{I as c}from"./slidev/default-BY7GIb9b.js";import{u as p,f as d}from"./slidev/context-Co-6DO2t.js";import"./index-CDGWvc22.js";import"./modules/shiki-D1VZkxQz.js";const b={__name:"ai.md__slidev_815",setup(f){const{$clicksContext:a,$frontmatter:i}=p();return a.setup(),(g,o)=>(l(),r(c,m(u(n(d)(n(i),814))),{default:s(()=>o[0]||(o[0]=[e("p",null,[e("strong",null,"Omarillo-3:"),t(" ⚖️ "),e("em",null,'"Ottima domanda. In questi casi, la responsabilità etica ricade sull’intenzione umana. L’IA è uno strumento, ma gli esseri umani sono coloro che ne decidono l’uso."')],-1),e("p",null,[e("strong",null,"Studente-4:"),t(" 😤 "),e("em",null,'"Però non è così semplice. Un algoritmo potrebbe creare situazioni di cyberbullismo senza un’intenzione diretta. Ad esempio, una piattaforma che promuove contenuti controversi per ottenere più interazioni."')],-1),e("p",null,[e("strong",null,"Omarillo-4:"),t(" 📈 "),e("em",null,'"Esattamente. Le piattaforme possono amplificare il male involontariamente. Per questo è fondamentale progettare sistemi etici che minimizzino questi rischi."')],-1),e("p",null,[e("strong",null,"Studente-5:"),t(),e("em",null,'"Ma anche se l’intenzione non è diretta, l’effetto sulla vittima è lo stesso. Le emozioni che prova sono reali."')],-1),e("p",null,[e("strong",null,"Omarillo-5:"),t(" 🌐 "),e("em",null,'"Proprio così. Questo dimostra che la linea tra reale e artificiale non conta quando si tratta delle conseguenze emotive. La sofferenza è reale, indipendentemente da come è generata."')],-1)])),_:1,__:[0]},16))}};export{b as default};
